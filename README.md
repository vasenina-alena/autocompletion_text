# autocompletion_text
## Исходные данные
Исходный файл **tweets.txt** был скачан по ссылке данной в уроке
* В папке "data" оставила только файлы train, val и test с расширением .csv
<br> **файлы tweets.txt, raw_dataset.csv и dataset_processed.csv не выкладывала из-за того, что ругается GitHub на большие объемы данных**
### Обучение LSTM и использование предобученой модели DistilGPT
Поскольку выполняла проект с использованием только мощности CPU своего компьютера при обучении LSTM использовала только половину данных из исходного файла и также ограничилась тремя эпохами 
## ВЫВОДЫ
В целом, **DistilGPT** показывает **значительно лучшие результаты** в плане качества и содержательности автодополнений по сравнению с LSTM.
<br> на это указывают как значения rouge-1 и rouge-2, которые в два раза превосходят значения для LSTM, так и непосредственное сравнение полученных текстов.
| Модель | rouge-1 | rouge-2|
|--------|---------|--------|
| LSTM| 0.3534 |  0.3050 |
| DistilGPT-2 | 0.6672 | 0.6164 |

На тестовой выборке DistilGPT-2 показала также хороший результат:
  * ROUGE-1: 0.6723;
  * ROUGE-2: 0.6203
